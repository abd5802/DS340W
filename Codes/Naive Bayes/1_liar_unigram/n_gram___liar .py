from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
import numpy as np
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.model_selection import train_test_split as tts
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.model_selection import cross_val_score
import csv
import pickle

texts = []
labels = []

with open('train.csv', 'r') as csv_file:
    csv_reader = csv.reader(csv_file)
    next(csv_reader)

    #words = []
    #c = len(csv_reader)
    for line in csv_reader:
    	texts.append(line[0])
        if line[1] == 'FALSE':
            labels.append(1)
        elif line[1] == 'TRUE':
            labels.append(0)

with open('test.csv', 'r') as csv_file:
    csv_reader = csv.reader(csv_file)
    next(csv_reader)

    #words = []
    #c = len(csv_reader)
    for line in csv_reader:
    	texts.append(line[0])
        if line[1] == 'FALSE':
            labels.append(1)
        elif line[1] == 'TRUE':
            labels.append(0)   

#print(texts)
'''
texts = [
	"good movies", "not a good movie", "did not like",
	"i like it", "good one"

]

print(texts)
labels = [
	"1","0","0","1","1"


]
'''
tfidf = TfidfVectorizer(min_df = 2, max_df = 0.5, ngram_range = (1,1), stop_words = 'english')
features = tfidf.fit_transform(texts)
pd.DataFrame(
	features.todense(),
	columns=tfidf.get_feature_names()
)


features = features.toarray() 






#print(tfidf.get_feature_names())

#x_train, x_test, y_train, y_test = tts(features, labels, test_size=0.2)

x_train = features[0:10240]
y_train = labels[0:10240]

x_test = features[10240:]
y_test = labels[10240:]




###classifiers
clf_nb = MultinomialNB()

#clf_svm = svm.SVC(kernel='linear')
#clf_lr = LogisticRegression()

#########


##model save
print("training start.........")
print(".")
print("nb start")
clf_nb.fit(x_train, y_train)
filename = 'nb.sav'
pickle.dump(clf_nb, open(filename, 'wb'))
print("nb done")



######################


##########################
filename = 'nb.sav'
loaded_model = pickle.load(open(filename, 'rb'))
#result = loaded_model.score(X, y)
#print(result)



pred = loaded_model.predict(x_test)

print("###################")
print(".")
print("test results: ")
print("---------nb---------------------")
print ("test_accuracy: ")
print (accuracy_score(y_test, pred))

print ("test_precision: ")
print (precision_score(y_test, pred, average="weighted"))

print ("test_recall: ")
print (recall_score(y_test, pred, average="weighted"))

print ("test_f1 ")
print (f1_score(y_test, pred, average="weighted"))




filename = 'nb_pickle.pickle'
pickle.dump((y_test,pred), open(filename, 'wb'))


